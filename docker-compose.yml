version: '3.8'

services:
  backend:
    image: carlostrevisan/ai-ethics-backend:latest
    container_name: triple-reasoning-backend
    ports:
      - "5001:5001"
    environment:
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - OPENROUTER_MODEL=${OPENROUTER_MODEL:-meta-llama/llama-3.3-70b-instruct}
      - PORT=5001
      - NODE_ENV=production
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  frontend:
    image: carlostrevisan/ai-ethics-frontend:latest
    container_name: triple-reasoning-frontend
    ports:
      - "3001:80"
    depends_on:
      - backend
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:80"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  default:
    name: triple-reasoning-network
